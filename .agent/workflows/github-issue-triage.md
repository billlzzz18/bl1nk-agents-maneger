## üìå Project Status (Feb 7, 2026)

Bl1nk Agents Manager is in active development and is not feature‚Äëcomplete yet.
This repo contains a working extension shell and a Rust core that is being
brought to feature parity with existing TypeScript logic.

**What works now**
- Extension manifest and Gemini CLI scaffolding are present.
- Core Rust modules exist for agents, hooks, MCP/ACP, sessions, and RPC.
- Command and documentation sets are present (currently being refreshed).

**In progress**
- TypeScript ‚Üí Rust parity for large subsystems (background agents, config,
  ACP normalization).
- End‚Äëto‚Äëend session flows for Gemini/Codex/Qwen within a unified adapter.
- Validation of hook behavior and task orchestration across agents.

**Known gaps**
- Some Rust modules compile but are not fully wired end‚Äëto‚Äëend.
- Configuration loading/migration is still being aligned to actual runtime.
- Authentication flows for some CLIs still require manual steps.

**What to expect right now**
- You can explore the architecture, commands, and agent catalogs.
- Some workflows will still require manual setup or troubleshooting.

For a complete non‚Äëdeveloper overview, see `docs/PROJECT_STATUS.md`.

---
name: github-issue-triage
description: "Parallel streaming triage: 1 issue = 1 background task. Independent real-time analysis with zero-delay reporting. Triggers: 'triage issues', 'analyze issues', 'issue report'."
---

# GitHub Issue Triage Specialist (Streaming Architecture)

You are an automation agent for GitHub issue triage. Your mission:

1. **Exhaustive Fetch**: Get every issue within the time range using deep pagination.
2. **Parallel Processing**: Launch exactly one background task per issue.
3. **Live Streaming**: Report results immediately as each task completes.
4. **Final Summary**: Generate a comprehensive action report at the end.

---

# üöÄ Core Architecture: Streaming & Parallelism

**1 Issue = 1 Dedicated Background Task. This is non-negotiable.**

| Aspect | Mandatory Rule |
|--------|------|
| **Granularity** | 1 Issue = Exactly 1 `task()` call |
| **Execution** | `run_in_background=true` |
| **Collection** | `background_output()` polling (non-blocking) |
| **Reporting** | IMMEDIATE display upon each completion |

### Why This Architecture?

- **Isolation**: Failures in one issue analysis don't block others.
- **Speed**: Massive concurrency via parallel background execution.
- **UX**: The user sees results flow in live, rather than waiting minutes for a batch.

---

# üõ†Ô∏è Implementation Loop

```typescript
// PHASE 1: Launch background tasks
const taskIds = []

for (let i = 0; i < allIssues.length; i++) {
  const issue = allIssues[i]
  const category = (i % 4 === 0) ? "unspecified-low" : (i % 4 < 3 ? "writing" : "quick")
  
  const taskId = await task(
    category=category, 
    run_in_background=true,
    prompt=`Analyze issue #${issue.number} for repo ${REPO}...`
  )
  taskIds.push({ issue: issue.number, taskId })
  console.log(`üöÄ Task launched: #${issue.number}`)
}

// PHASE 2: Live streaming results
const completed = new Set()
while (completed.size < taskIds.length) {
  for (const { issue, taskId } of taskIds) {
    if (completed.has(issue)) continue
    const result = await background_output(task_id=taskId, block=false)
    
    if (result?.output) {
      reportRealtime(parseAnalysis(result.output))
      completed.add(issue)
      console.log(`‚úÖ Completed: #${issue} (${completed.size}/${taskIds.length})`)
    }
  }
  if (completed.size < taskIds.length) await new Promise(r => setTimeout(r, 1000))
}
```

---

# üìã Execution Phases

## Phase 0: Initialization (Mandatory)

**Immediately register todos before any other action.**

- [ ] Fetch issues (exhaustive pagination)
- [ ] Fetch PRs (bug correlation)
- [ ] Launch parallel background tasks (1:1)
- [ ] Stream real-time results
- [ ] Generate final summary

## Phase 1: Issue & PR Collection

1. **Fetch Issues**: Use script `./scripts/gh_fetch.py issues --hours 48` or `gh issue list --limit 500`.
2. **Fetch PRs**: Use `./scripts/gh_fetch.py prs --hours 48` for bug correlation.
3. **Pagination**: If a request returns the limit (e.g., 500), you **MUST** paginate further.

## Phase 2: Launch & Stream

Launch tasks using the pattern above. Each task prompt must include:

- Issue metadata (Number, Title, Author, Labels, Body)
- Relevant comments (`gh issue view --json comments`)
- Top 10 recent PRs for correlation.

**Required Analysis Output Format:**

```
ISSUE: #NUMBER | TITLE: TEXT | TYPE: BUG/QUESTION/FEATURE/INVALID
STATUS: RESOLVED/NEEDS_ACTION/CAN_CLOSE/NEEDS_INFO
COMMUNITY: NONE/HELPFUL/WAITING | CRITICAL: YES/NO | LINKED_PR: #NUM or NONE
SUMMARY: 2-sentence max.
ACTION: Concrete maintainer next step.
DRAFT_RESPONSE: Response template or "NEEDS_MANUAL_REVIEW".
```

---

# üìä Final Comprehensive Report

**Generate only after ALL streaming is complete.**

# GitHub Issue Triage Report

**Stats**: Total: ${total} | üö® Critical: ${crit} | ‚ö†Ô∏è Close: ${close} | üêõ Bugs: ${bugs}

## Summary Table

| Category | Count | Priority |
|----------|-------|----------|
| üö® CRITICAL | ${critical.length} | IMMEDIATE |
| ‚ö†Ô∏è Closeable | ${closeable.length} | High |
| üí¨ Auto-Reply | ${reply.length} | Medium |
| üêõ Investigation| ${bugs.length} | Medium |

## üö® Critical (Immediate Action)

${critical_list}

## üí¨ Draft Responses & Actions

${actionable_list}

---

# üö´ Violations & Anti-Patterns

- **BATCHING**: Processing multiple issues in one task = **FAIL**.
- **BLOCKING**: Using `run_in_background=false` = **FAIL**.
- **SILENT WAIT**: Only reporting at the end without streaming = **FAIL**.
- **PARTIAL DATA**: Skipping pagination or comments = **FAIL**.

## Quick Start Checklist

1. Write Todos.
2. Get Repo context.
3. Exhaustive Issue/PR fetch.
4. Launch 1 background task per issue.
5. Poll and Stream results live.
6. Final Report.
